{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import recsys as rs\n",
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data/train_final.csv','\\t')\n",
    "tr_info = pd.read_csv('Data/tracks_final.csv','\\t')\n",
    "tgt_pl = pd.read_csv('Data/target_playlists.csv','\\t')\n",
    "tgt_tr = pd.read_csv('Data/target_tracks.csv','\\t')\n",
    "attributes = ['artist_id', 'album', 'tags', 'playcount']\n",
    "attributes_to_trim = ['tags']\n",
    "n_min_attr = 90\n",
    "n_el_sim = 15\n",
    "measure = 'dot'\n",
    "shrinkage = 0\n",
    "min_tracks_in_playlist=10\n",
    "test_percentage=20\n",
    "n_tracks_toremove=5\n",
    "seed=2517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, tgt_tracks, tgt_playlists = rs.split_train_test(dataset, min_tracks_in_playlist, test_percentage, n_tracks_toremove, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_info_fixed = rs.fix_tracks_format(tr_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_info_fixed = rs.delete_low_frequency_attributes(tr_info_fixed, attributes_to_trim, n_min_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IX_items, IX_tgt_items, IX_tgt_playlists, IX_attr = rs.create_sparse_indexes(tracks_info=tr_info_fixed, tracks_reduced=tgt_tracks, playlists=tgt_playlists, attr_list=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICM = rs.create_ICM(tr_info_fixed, IX_items, IX_attr, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 0 users ratings over 4420\n",
      "Calculated 1000 users ratings over 4420\n",
      "Calculated 2000 users ratings over 4420\n",
      "Calculated 3000 users ratings over 4420\n",
      "Calculated 4000 users ratings over 4420\n"
     ]
    }
   ],
   "source": [
    "URM = rs.create_tgt_URM(IX_tgt_playlists, IX_items, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM = URM.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICM = sps.vstack([ICM.tocsr(), URM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ICM = rs.ICM_idf_regularization(ICM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 0 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 1000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 2000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 3000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 4000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 5000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 6000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 7000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 8000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 9000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 10000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 11000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 12000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 13000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 14000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 15000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 16000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 17000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 18000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 19000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 20000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 21000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 22000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 23000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 24000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 25000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 26000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 27000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 28000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 29000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 30000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 31000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 32000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 33000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 34000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 35000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 36000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 37000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 38000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 39000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 40000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 41000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 42000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 43000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 44000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 45000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 46000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 47000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 48000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 49000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 50000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 51000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 52000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 53000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 54000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 55000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 56000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 57000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 58000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 59000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 60000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 61000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 62000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 63000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 64000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 65000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 66000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 67000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 68000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 69000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 70000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 71000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 72000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 73000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 74000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 75000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 76000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 77000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 78000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 79000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 80000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 81000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 82000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 83000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 84000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 85000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 86000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 87000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 88000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 89000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 90000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 91000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 92000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 93000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 94000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 95000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 96000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 97000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 98000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 99000 similarities over 100000 with dot measure and 0 shrinkage.\n"
     ]
    }
   ],
   "source": [
    "S = rs.create_Smatrix(ICM, n_el_sim, measure, shrinkage, IX_tgt_items, IX_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended 0 users over 4420\n",
      "Recommended 1000 users over 4420\n",
      "Recommended 2000 users over 4420\n",
      "Recommended 3000 users over 4420\n",
      "Recommended 4000 users over 4420\n"
     ]
    }
   ],
   "source": [
    "recommendetions = np.array([])\n",
    "for p in IX_tgt_playlists.values:\n",
    "            avg_sims = URM[p,:].dot(S).toarray().ravel()\n",
    "            top = rs.top5_outside_playlist(avg_sims, p, train, IX_tgt_playlists, IX_tgt_items)\n",
    "            recommendetions = np.append(recommendetions, rs.sub_format(top))\n",
    "            if (p % 1000 == 0):\n",
    "                print('Recommended ' + str(p) + ' users over ' + str(IX_tgt_playlists.values.shape[0]))\n",
    "recs = pd.DataFrame({'playlist_id' : IX_tgt_playlists.index.values, 'track_ids' : recommendetions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated AP for playlist #0\n",
      "Calculated AP for playlist #1000\n",
      "Calculated AP for playlist #2000\n",
      "Calculated AP for playlist #3000\n",
      "Calculated AP for playlist #4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03975037707390631"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_eval = rs.evaluate(recs, test, 'MAP')\n",
    "map_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
