{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import recsys as rs\n",
    "import json\n",
    "import notipy\n",
    "import random\n",
    "import TopSimilarRecommender as TSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train_final.csv','\\t')\n",
    "tr_info = pd.read_csv('Data/tracks_final.csv','\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, tgt_tracks, tgt_playlists = rs.split_train_test(train, 10, 20, 5, 2517)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dict = {'tracks_info' : tr_info, \n",
    "            'attributes' : ['artist_id', 'album', 'tags', 'playcount'],\n",
    "            'attributes_to_prune' : ['tags'],\n",
    "            'tgt_tracks' : tgt_tracks,\n",
    "            'n_min_attr' : 5,\n",
    "            'idf' : True,\n",
    "            'measure' : 'dot',\n",
    "            'shrinkage' : 0,\n",
    "            'n_el_sim' : 20}\n",
    "\n",
    "recommend_dict = {'tgt_playlists' : tgt_playlists,\n",
    "                  'train_playlists_tracks_pairs' : train, \n",
    "                  'normalize' : False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed dataset\n",
      "Calculated Indices\n",
      "ICM built\n",
      "Pruning attributes.\n",
      "Number of attributes before pruning is: 77041\n",
      "Number of attributes after pruning is: 14737\n",
      "Computed 0 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 1000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 2000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 3000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 4000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 5000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 6000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 7000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 8000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 9000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 10000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 11000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 12000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 13000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 14000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 15000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 16000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 17000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 18000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 19000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 20000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 21000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 22000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 23000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 24000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 25000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 26000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 27000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 28000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 29000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 30000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 31000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 32000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 33000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 34000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 35000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 36000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 37000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 38000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 39000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 40000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 41000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 42000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 43000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 44000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 45000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 46000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 47000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 48000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 49000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 50000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 51000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 52000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 53000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 54000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 55000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 56000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 57000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 58000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 59000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 60000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 61000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 62000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 63000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 64000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 65000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 66000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 67000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 68000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 69000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 70000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 71000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 72000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 73000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 74000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 75000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 76000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 77000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 78000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 79000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 80000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 81000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 82000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 83000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 84000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 85000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 86000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 87000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 88000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 89000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 90000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 91000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 92000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 93000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 94000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 95000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 96000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 97000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 98000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Computed 99000 similarities over 100000 with dot measure and 0 shrinkage.\n",
      "Similarity built\n",
      "Model fitted!\n"
     ]
    }
   ],
   "source": [
    "rec = TSR.TopSimilarRecommender()\n",
    "rec.fit(**fit_dict)\n",
    "notipy.notify('Model fitted!')\n",
    "print('Model fitted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 0 users ratings over 4420\n",
      "Calculated 1000 users ratings over 4420\n",
      "Calculated 2000 users ratings over 4420\n",
      "Calculated 3000 users ratings over 4420\n",
      "Calculated 4000 users ratings over 4420\n",
      "URM built\n",
      "Recommended 0 users over 4420\n",
      "Recommended 1000 users over 4420\n",
      "Recommended 2000 users over 4420\n",
      "Recommended 3000 users over 4420\n",
      "Recommended 4000 users over 4420\n",
      "Recommending completed!\n"
     ]
    }
   ],
   "source": [
    "recommendetions = rec.recommend(**recommend_dict)\n",
    "notipy.notify('Recommending completed!')\n",
    "print('Recommending completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated AP for playlist #0\n",
      "Calculated AP for playlist #1000\n",
      "Calculated AP for playlist #2000\n",
      "Calculated AP for playlist #3000\n",
      "Calculated AP for playlist #4000\n",
      "Evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "map_eval = rs.evaluate(recommendetions, test, 'MAP')\n",
    "notipy.notify('Evaluation completed!')\n",
    "print('Evaluation completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_data = {'recommender_type' : rec.__class__.__name__,\n",
    "            'fit_parameters' : {'attributes' : fit_dict['attributes'],\n",
    "                                'attributes_to_prune' : fit_dict['attributes_to_prune'],\n",
    "                                'n_min_attr' : fit_dict['n_min_attr'],\n",
    "                                'idf' : fit_dict['idf'],\n",
    "                                'measure' : fit_dict['measure'],\n",
    "                                'shrinkage' : fit_dict['shrinkage'],\n",
    "                                'n_el_sim' : fit_dict['n_el_sim']},\n",
    "            'recommend_parameters' : {'normalize' : recommend_dict['normalize']},\n",
    "            'evaluation_result' : map_eval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run data saved!\n"
     ]
    }
   ],
   "source": [
    "with open('runs_data.json', 'a') as fp:\n",
    "    json.dump(run_data, fp, indent=2)\n",
    "    fp.write('\\n')\n",
    "notipy.notify('Run data saved!')\n",
    "print('Run data saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061107088989441616"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
