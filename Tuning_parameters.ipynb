{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import recsys as rs\n",
    "import notipy\n",
    "import math\n",
    "import sys\n",
    "import TopSimilarRecommender as TSR\n",
    "import ItemBasedRecommender as IBR\n",
    "import UserBasedRecommender as UBR\n",
    "import random\n",
    "from scipy import sparse as sps\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train_final.csv','\\t')\n",
    "tracks = pd.read_csv('Data/tracks_final.csv','\\t')\n",
    "pl_info = pd.read_csv('Data/playlists_final.csv','\\t')\n",
    "tgt_playlists = pd.read_csv('Data/target_playlists.csv','\\t')\n",
    "tgt_tracks = pd.read_csv('Data/target_tracks.csv','\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9129, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test, tgt_tracks, tgt_playlists = rs.train_test_split_interface(train, 10, 20, 5, 2517)\n",
    "tgt_playlists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed dataset\n",
      "Calculated Indices\n",
      "ICM built\n",
      "ICM regularized with IDF!\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Similarity built\n",
      "Model fitted!\n"
     ]
    }
   ],
   "source": [
    "tsr= TSR.TopSimilarRecommender(attributes=['artist_id', 'album'],idf=True, n_min_attr=90, n_el_sim=120)\n",
    "tsr.fit(tracks,tgt_tracks,multiprocessing=True)#, saved_similarity='BuiltStructures/tsr_sim_65el_idfTrue_artist_album_playcount.npz')\n",
    "print('Model fitted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Indices\n",
      "Model URM built\n",
      "Model URM regularized with IDF!\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Model fitted!\n"
     ]
    }
   ],
   "source": [
    "ibr = IBR.ItemBasedRecommender(idf=True, shrinkage=10,n_el_sim=140)\n",
    "ibr.fit(tracks,train,tgt_tracks, multiprocessing=True)#, saved_similarity='BuiltStructures/ibr_sim_65el_h10_idfTrue.npz')\n",
    "print('Model fitted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Indices\n",
      "Model URM built\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Model fitted!\n"
     ]
    }
   ],
   "source": [
    "tsr_tag= IBR.ItemBasedRecommender(idf=False, shrinkage=10,n_el_sim=140)\n",
    "tsr_tag.fit(tracks,train,tgt_tracks, multiprocessing=True)#, save_sim=True)\n",
    "print('Model fitted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Indices\n",
      "(45649, 100000)\n",
      "Model URM built\n",
      "Computed 0 similarities over chunk of 11412 elements.\n",
      "Computed 0 similarities over chunk of 11412 elements.\n",
      "Computed 0 similarities over chunk of 11412 elements.\n",
      "Computed 0 similarities over chunk of 11413 elements.\n",
      "Computed 5000 similarities over chunk of 11412 elements.\n",
      "Computed 5000 similarities over chunk of 11413 elements.\n",
      "Computed 5000 similarities over chunk of 11412 elements.\n",
      "Computed 5000 similarities over chunk of 11412 elements.\n",
      "Computed 10000 similarities over chunk of 11412 elements.\n",
      "Computed 10000 similarities over chunk of 11412 elements.\n",
      "Computed 10000 similarities over chunk of 11413 elements.\n",
      "Computed 10000 similarities over chunk of 11412 elements.\n",
      "Similarity built\n",
      "Model fitted!\n"
     ]
    }
   ],
   "source": [
    "UBR = importlib.reload(UBR)\n",
    "ubr = UBR.UserBasedRecommender(measure='imp_cos', shrinkage=10,n_el_sim =10)\n",
    "ubr.fit(tracks,train,tgt_playlists,multiprocessing=True)#, saved_similarity='BuiltStructures/ubr_sim_65el_impcos.npz')\n",
    "print('Model fitted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URM built\n"
     ]
    }
   ],
   "source": [
    "_, _, IX_tgt_playlists, _ = rs.create_sparse_indexes(playlists=tgt_playlists)\n",
    "_, _, IX_playlists, _ = rs.create_sparse_indexes(tracks_info=tracks, playlists=train, tracks_reduced=tracks)\n",
    "URM_UBR =rs.create_UBR_URM(IX_playlists, tsr.IX_tgt_items, train)\n",
    "URM = rs.create_tgt_URM(IX_tgt_playlists, tsr.IX_items, train)\n",
    "print('URM built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsr.S =tsr.S.tocsr()\n",
    "tsr_tag.S =tsr_tag.S.tocsr()\n",
    "ibr.S =ibr.S.tocsr()\n",
    "ubr.S =ubr.S.T.tocsr()\n",
    "URM = URM.tocsr()\n",
    "URM_UBR= URM_UBR.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "div_t = tsr.S.sum(axis=0)\n",
    "div_tt = tsr_tag.S.sum(axis=0)\n",
    "div_i = ibr.S.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended 0 users over 9129\n",
      "Recommended 1000 users over 9129\n",
      "Recommended 2000 users over 9129\n",
      "Recommended 3000 users over 9129\n",
      "Recommended 4000 users over 9129\n",
      "Recommended 5000 users over 9129\n",
      "Recommended 6000 users over 9129\n",
      "Recommended 7000 users over 9129\n",
      "Recommended 8000 users over 9129\n",
      "Recommended 9000 users over 9129\n"
     ]
    }
   ],
   "source": [
    "recommendetions = np.array([])\n",
    "H_t=60\n",
    "H_i=10\n",
    "H_tt=60\n",
    "ubr.S = ubr.S.tocsr()\n",
    "for p in IX_tgt_playlists.values:\n",
    "    avg_sims_t = URM[p,:].dot(tsr.S).toarray().ravel()\n",
    "    avg_sims_t = np.array(avg_sims_t/(div_t+H_t+1e-6)).ravel()\n",
    "    avg_sims_i = URM[p,:].dot(ibr.S).toarray().ravel()\n",
    "    avg_sims_i = np.array(avg_sims_i/(div_i+H_i+1e-6)).ravel()\n",
    "    avg_sims_u = ubr.S[p,:].dot(URM_UBR).toarray().ravel()\n",
    "    avg_sims_tt = URM[p,:].dot(tsr_tag.S).toarray().ravel()\n",
    "    avg_sims_tt = np.array(avg_sims_tt/(div_tt+H_tt+1e-6)).ravel()\n",
    "    avg_sims= np.array(avg_sims_t*0.4+avg_sims_tt*0.5+avg_sims_u*0.1).ravel()\n",
    "    top = rs.top5_outside_playlist(avg_sims, p, train, IX_tgt_playlists, tsr.IX_tgt_items, False, False)\n",
    "    recommendetions = np.append(recommendetions, rs.sub_format(top))\n",
    "    if (p % 1000 == 0):\n",
    "        print('Recommended ' + str(p) + ' users over ' + str(IX_tgt_playlists.values.shape[0]))\n",
    "rec_tsr =  pd.DataFrame({'playlist_id' : IX_tgt_playlists.index.values, 'track_ids' : recommendetions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "map_eval = rs.evaluate(rec_tsr, test, 'MAP')\n",
    "print('Evaluation completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08978968123562385"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as csv!\n"
     ]
    }
   ],
   "source": [
    "rec_tsr.to_csv('Submissions/ensemble_submission_new_matrices_tag_040501_ibr_140el_idfFalse_ubr10el_Hi10.csv', index=False)\n",
    "print('Results saved as csv!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0.09034834045350097\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#040501 h 60 100 60 ibr idf true 0.08922737065030964 <-- The one on Kaggle but h_i =100 on k hi=60 ?\n",
    "#same, idf False 0.08978968123562385 <-- Hi =60\n",
    "#idf false, hi=100 0.08922737065030964\n",
    "#idf false, hi=30  0.09012816299704365\n",
    "#hi 10 0.09034834045350097 <- BEST\n",
    "# no shrinkage 0.0894201628509889\n",
    "#5 0.08995508818052482\n",
    "#15 0.09026910578011577\n",
    "#hi 10, idf True 0.09034834045350097\n",
    "#----------\n",
    "#Ht =10 0.0896344981195468\n",
    "#ht 30 0.09002811552926672\n",
    "#ht 50 0.09025413517362361\n",
    "#ht 100 0.08997005878701698\n",
    "#ht 70 0.0902066673969413"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
