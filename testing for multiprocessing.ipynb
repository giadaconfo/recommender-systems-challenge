{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recsys as rs\n",
    "import TopSimilarRecommender as TSR\n",
    "import json\n",
    "import time\n",
    "import notipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/train_final.csv','\\t')\n",
    "tracks = pd.read_csv('Data/tracks_final.csv','\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, tgt_tracks, tgt_playlists = rs.train_test_split_interface(data, 10, 20, 5, 2517)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_dict_tsr = {'attributes' : ['artist_id', 'album', 'playcount'],\n",
    "                'n_min_attr' : 90,\n",
    "                'idf' : True,\n",
    "                'measure' : 'dot',\n",
    "                'shrinkage' : 0,\n",
    "                'n_el_sim' : 65}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed dataset\n",
      "Calculated Indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 51/100000 [00:00<03:18, 504.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICM built\n",
      "ICM regularized with IDF!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [42:36<00:00, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fitstart = time.time()\n",
    "tsr = TSR.TopSimilarRecommender(**fit_dict_tsr)\n",
    "tsr.fit(tracks, tgt_tracks, multiprocessing=False)\n",
    "fitend = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9129 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URM built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9129/9129 [35:21<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "recstart = time.time()\n",
    "recs = tsr.recommend(tgt_playlists, train, normalize=True, sim_check=False, secondary_sorting=False, multiprocessing=False)\n",
    "recend = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit completed in 2583.411411046982 seconds.\n",
      "Recommendetion completed in 2121.9474737644196 seconds.\n"
     ]
    }
   ],
   "source": [
    "print('Fit completed in '+str(float(fitend-fitstart))+' seconds.')\n",
    "print('Recommendetion completed in '+str(float(recend-recstart))+' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.07642640668930567\n"
     ]
    }
   ],
   "source": [
    "map_eval = rs.evaluate(recs, test, 'MAP')\n",
    "print('MAP score: '+str(map_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_data = {'recommender' : tsr.__class__.__name__,\n",
    "            'fit_parameters' : fit_dict_tsr,\n",
    "            'evaluation' : map_eval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('runs_data.json', 'a') as fp:\n",
    "    json.dump(run_data, fp, indent=2)\n",
    "    fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notipy.notify('MAP score: '+str(map_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed dataset\n",
      "Calculated Indices\n",
      "ICM built\n",
      "ICM regularized with IDF!\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Similarity built\n",
      "URM built\n",
      "Computed 0 recommendetions over chunk of 2282 elements.\n",
      "Computed 0 recommendetions over chunk of 2282 elements.\n",
      "Computed 0 recommendetions over chunk of 2282 elements.\n",
      "Computed 0 recommendetions over chunk of 2283 elements.\n",
      "Computed 1000 recommendetions over chunk of 2282 elements.\n",
      "Computed 1000 recommendetions over chunk of 2282 elements.\n",
      "Computed 1000 recommendetions over chunk of 2282 elements.\n",
      "Computed 1000 recommendetions over chunk of 2283 elements.\n",
      "Computed 2000 recommendetions over chunk of 2282 elements.\n",
      "Computed 2000 recommendetions over chunk of 2282 elements.\n",
      "Computed 2000 recommendetions over chunk of 2282 elements.\n",
      "Computed 2000 recommendetions over chunk of 2283 elements.\n",
      "MAP score: 0.04872822872165664\n"
     ]
    }
   ],
   "source": [
    "fitstart = time.time()\n",
    "tsr = TSR.TopSimilarRecommender(**fit_dict_tsr)\n",
    "tsr.fit(tracks,tgt_tracks, multiprocessing=True)\n",
    "fitend = time.time()\n",
    "recstart = time.time()\n",
    "recs = tsr.recommend(tgt_playlists, train, normalize=True, sim_check=False, secondary_sorting=False, multiprocessing=True)\n",
    "recend = time.time()\n",
    "map_eval = rs.evaluate(recs, test, 'MAP')\n",
    "print('MAP score: '+str(map_eval))\n",
    "run_data = {'recommender' : tsr.__class__.__name__,\n",
    "            'fit_parameters' : fit_dict_tsr,\n",
    "            'evaluation' : map_eval}\n",
    "with open('runs_data.json', 'a') as fp:\n",
    "    json.dump(run_data, fp, indent=2)\n",
    "    fp.write('\\n')\n",
    "notipy.notify('MAP score: '+str(map_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed dataset\n",
      "Calculated Indices\n",
      "ICM built\n",
      "ICM regularized with IDF!\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 0 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 5000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 10000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 15000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Computed 20000 similarities over chunk of 25000 elements.\n",
      "Similarity built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9129 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URM built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9129/9129 [34:36<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP score: 0.07672472340891744\n"
     ]
    }
   ],
   "source": [
    "fitstart = time.time()\n",
    "tsr = TSR.TopSimilarRecommender(**fit_dict_tsr)\n",
    "tsr.fit(tracks,tgt_tracks, multiprocessing=True)\n",
    "fitend = time.time()\n",
    "recstart = time.time()\n",
    "recs = tsr.recommend(tgt_playlists, train, normalize=True, sim_check=False, secondary_sorting=False, multiprocessing=False)\n",
    "recend = time.time()\n",
    "map_eval = rs.evaluate(recs, test, 'MAP')\n",
    "print('MAP score: '+str(map_eval))\n",
    "run_data = {'recommender' : tsr.__class__.__name__,\n",
    "            'fit_parameters' : fit_dict_tsr,\n",
    "            'evaluation' : map_eval}\n",
    "with open('runs_data.json', 'a') as fp:\n",
    "    json.dump(run_data, fp, indent=2)\n",
    "    fp.write('\\n')\n",
    "notipy.notify('MAP score: '+str(map_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
